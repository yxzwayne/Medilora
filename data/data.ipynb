{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "df = pd.read_csv(\"patient_data.csv\")\n",
    "n = len(df.index)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the `notes` column of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_str(input):\n",
    "#     input = input.split()\n",
    "#     input = \" \".join(input).strip()\n",
    "#     return input\n",
    "\n",
    "# df[\"notes\"] = df[\"notes\"].apply(clean_str)\n",
    "\n",
    "# # Assuming df is your DataFrame\n",
    "# with open(f\"anonymized_patient_notes.txt\", 'w', encoding='utf-8') as file:\n",
    "#     for _, row in df.iterrows():\n",
    "#         file.write(row['notes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pprint import pprint\n",
    "import json\n",
    "\n",
    "\n",
    "def ollama_request(prompt, model=\"hermes\"):\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    param = {\"model\": \"hermes\", \"prompt\": prompt, \"stream\": False, \"raw\": True}\n",
    "    res = requests.post(url, json=param).json()\n",
    "    pprint(res)\n",
    "    bot_response = res[\"response\"]\n",
    "    sec = res[\"eval_duration\"] / 1000000000\n",
    "    tok_s = res[\"eval_count\"] / sec\n",
    "    return bot_response\n",
    "\n",
    "\n",
    "def obtain_qa(note, model=\"hermes\"):\n",
    "    q_prompt = f'MEDICAL NOTE: \"\"\"\\n{note}\"\"\" \\nBased on the given medical note, what is be the single most probably inquiry or question the patient asked to the doctor? '\n",
    "    q = ollama_request(q_prompt, model)\n",
    "\n",
    "    ans_prompt = f'PATIENT QUESTION:  \"\"\"\\n{q}\"\"\" \\n MEDICAL NOTE: \"\"\"\\n{note}\"\"\" \\nBased on the given medical note and patient question, construct a concise and terse paragraph of a top professional doctors response in 3 to 4 sentences. '\n",
    "    ans = ollama_request(ans_prompt)\n",
    "\n",
    "    return q, ans\n",
    "\n",
    "\n",
    "def obtain_qa_single_run(note, model=\"hermes\"):\n",
    "    prompt = f'MEDICAL NOTE: \"\"\"\\n{note}\"\"\" \\nBased on the given medical note, construct one `Question` and `Answer` pair between the patient and the doctor in JSON format with exactly one pair of `Question` and `Answer`. The patients question includes clear and detailed description of the problem relevant in the medical note. The doctors answer is in first person perspective, and includes reasoning and details, such as sympotoms, diagnosis, inference, suggestions, medications. Both questions and answers should be concise, straight to the point and highly medically relevant. '\n",
    "\n",
    "    res = ollama_request(prompt, model)\n",
    "    return res\n",
    "\n",
    "\n",
    "r = random.randint(0, n)\n",
    "\n",
    "sample_note = df.iloc[r].notes\n",
    "\n",
    "# q, ans = obtain_qa(sample_note)\n",
    "# print(f\"==== question: {q}\")\n",
    "# print(f\"==== answer: {ans}\")\n",
    "\n",
    "print(f\"\\n\\n {obtain_qa_single_run(sample_note, 'neural')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
